{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "0urkLzHNDJOR",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "## 3. Seq2Seq Machine Translation with Attention\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "ykQ7GalMOq1U",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "In this problem we will implement a neural network that translates sentences from French to English. This is made possible by the simple but powerful idea of the sequence to sequence network, in which two recurrent neural networks work together to transform one sequence to another. In its vanilla version, an encoder network condenses an input sequence into a vector, and a decoder network unfolds that vector into a new sequence. To improve upon this model, we’ll use an attention mechanism, which lets the decoder learn to focus over a specific range of the input sequence. <br/>\n",
        "The architecture of our network is inspired by (but not exactly similar to) the neural machine translation model proposed by [1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "VEmGY0ueXv39",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
        "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from typing import List, Dict\n",
        "from pprint import pprint\n",
        "import unicodedata\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "import random\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "Z0FojtjueMGk",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "### 3.1 Downloading and Reading the Data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "HKhtPobmfEPc",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "The data for this problem is a set of many thousands of English to French translation pairs. First let's download the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "oE6nWGOIeLZt",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "outputId": "4a9f5113-a7e2-4daa-a6a8-1cc2d6d6bac3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! wget https://download.pytorch.org/tutorial/data.zip\n",
        "! unzip -q data.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-12 21:25:07--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 108.138.94.103, 108.138.94.65, 108.138.94.113, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|108.138.94.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   2.75M  6.18MB/s    in 0.4s    \n",
            "\n",
            "2023-10-12 21:25:08 (6.18 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "F9IGe8h0ffCc",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Here is a sneak peek at our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "3tFcjYuxfPB3",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "outputId": "97b2868a-336b-4419-8875-ae1f9cee21db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "DATA_PATH = 'data/eng-fra.txt'\n",
        "! head -n 10 $DATA_PATH"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go.\tVa !\n",
            "Run!\tCours !\n",
            "Run!\tCourez !\n",
            "Wow!\tÇa alors !\n",
            "Fire!\tAu feu !\n",
            "Help!\tÀ l'aide !\n",
            "Jump.\tSaute.\n",
            "Stop!\tÇa suffit !\n",
            "Stop!\tStop !\n",
            "Stop!\tArrête-toi !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "jI_t9Pszfjqy",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "As you can see, every line contains a sentence in English and its translated version in French (Sentences are sorted by their length, so the first few sentences are very short)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "CMiPqhayYS2S",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "outputId": "b4750e34-cf4c-4137-b5c9-90bd4533493a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Setting the device\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)\n",
        "\n",
        "# Feel free to use the following variables wherever you like throughout the notebook\n",
        "START_TOKEN = '<START>'\n",
        "END_TOKEN = '<END>'\n",
        "PAD_TOKEN = '<PAD>'\n",
        "\n",
        "PAD_IDX = 0\n",
        "START_IDX = 1\n",
        "END_IDX = 2\n",
        "\n",
        "\n",
        "# Function for setting the random seed for reproducibility\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if DEVICE == torch.device(\"cuda\"):\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.cuda.empty_cache()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "VHGg20qDMkdf",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Let's define some functions to read the data from file and preprocess it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "PNGgkIyGgSW4",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "      c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "\n",
        "def read_corpus(path):\n",
        "    \"\"\"Reads the corpus from the file.\n",
        "\n",
        "    path: corpus file's path\n",
        "    \"\"\"\n",
        "    print(\"Reading the corpus...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open(path, encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    src_sents = [s[1].split() for s in pairs]\n",
        "    # Marking the beginning and end of target sentences with <START> and <END>\n",
        "    tgt_sents = [[START_TOKEN] + s[0].split() + [END_TOKEN] for s in pairs]\n",
        "\n",
        "    return src_sents, tgt_sents"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "4fZBL9vn27HH",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Let's read the corpus and print a couple of sentences of it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "pfofaz073G1v",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "outputId": "493e9de3-e773-4266-fdbd-dd7e6245d756",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "src_sents, tgt_sents = read_corpus(DATA_PATH)\n",
        "pprint(src_sents[:5])\n",
        "pprint(tgt_sents[:5])\n",
        "\n",
        "print('\\nNumber of sentences', len(src_sents))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading the corpus...\n",
            "[['va', '!'],\n",
            " ['cours', '!'],\n",
            " ['courez', '!'],\n",
            " ['ca', 'alors', '!'],\n",
            " ['au', 'feu', '!']]\n",
            "[['<START>', 'go', '.', '<END>'],\n",
            " ['<START>', 'run', '!', '<END>'],\n",
            " ['<START>', 'run', '!', '<END>'],\n",
            " ['<START>', 'wow', '!', '<END>'],\n",
            " ['<START>', 'fire', '!', '<END>']]\n",
            "\n",
            "Number of sentences 135842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "BEXjU-VyfpjZ",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "### 3.2 Vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "bZ_iARJSqsqy",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "As we need the Vocab class you implemented in Problem 1 here, copy your implementaion in the following cell (or copy your code into a .py file and import it from there)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "id": "XCvF_KrVX294",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "class Vocab:\n",
        "    def __init__(self, word2id=None):\n",
        "        \"\"\"Constructor of Vocab\n",
        "\n",
        "        word2id: dictionary that maps tokens to their ids.\n",
        "        \"\"\"\n",
        "        self.pad_token = '<PAD>'\n",
        "        self.end_token = '<END>'\n",
        "        self.start_token = '<START>'\n",
        "        self.unk_token = '<UNK>'\n",
        "\n",
        "        if word2id is None:\n",
        "            self.word2id = {self.pad_token: 0,\n",
        "                            self.start_token: 1,\n",
        "                            self.end_token: 2,\n",
        "                            self.unk_token: 3}\n",
        "            self.size = 4\n",
        "        else:\n",
        "            self.word2id = word2id\n",
        "            self.size = len(self.word2id)\n",
        "\n",
        "        self.id2word = {v: k for (k, v) in self.word2id.items()}\n",
        "\n",
        "    def build(self, tokenized_corpus: List[List[str]], size=None, min_freq=None):\n",
        "        \"\"\"Builds the vocab from a tokenized corpus.\n",
        "\n",
        "        tokenized_corpus: corpus as a list of list of tokens (strings)\n",
        "        size: Final size of (number of unique tokens in) our vocab\n",
        "        min_freq: minimum frequency\n",
        "        \"\"\"\n",
        "        tokens2freq = Counter(chain(*tokenized_corpus))  # dict that maps unique tokens to their freqs in the corpus\n",
        "        frequent_tokens = []\n",
        "\n",
        "        if size == None or min_freq == None:\n",
        "          frequent_tokens = tokenized_corpus\n",
        "        else:\n",
        "          frequent_tokens = [x for x in tokenized_corpus if counter[x] > min_freq ]\n",
        "        if not (size == None):\n",
        "          if size > len (frequent_tokens) :\n",
        "            frequent_tokens =  frequent_tokens[0:size]\n",
        "        pass\n",
        "\n",
        "        for token in frequent_tokens:\n",
        "            self.add_token(token)\n",
        "\n",
        "    def get_token_by_id(self, t_id: int) -> str:\n",
        "        \"\"\"Returns the token with the corresponding id in the vocab.\n",
        "        If the id is not valid, returns None.\n",
        "\n",
        "        t_id: token id\n",
        "        \"\"\"\n",
        "        return self.id2word.get(t_id, None)\n",
        "\n",
        "    def get_id_by_token(self, token: str) -> int:\n",
        "        \"\"\"Returns the id of the token in the vocab. If the token does not exist,\n",
        "        returns the id of <UNK> token.\n",
        "\n",
        "        token: token (as a string) for which the id should be returned.\n",
        "        \"\"\"\n",
        "        return self.word2id.get(token, self.word2id[self.unk_token])\n",
        "\n",
        "    def add_token(self, token: str):\n",
        "        \"\"\"Adds the token to the vocab's data structures\n",
        "        token: token as a string\n",
        "        \"\"\"\n",
        "\n",
        "        for t in token:\n",
        "          if t not in self.word2id:\n",
        "            self.word2id[t] = self.size\n",
        "            self.id2word[self.size] = t\n",
        "            self.size += 1\n",
        "\n",
        "        pass\n",
        "\n",
        "\n",
        "    def tokens2ids(self, sents):\n",
        "        \"\"\"Convert list of words or list of sentences of tokens\n",
        "        into list or list of list of indices.\n",
        "\n",
        "        sents: input sentences as List[List[str]] (multiple sentences) or List[str]\n",
        "        (single sentence)\n",
        "        \"\"\"\n",
        "\n",
        "        if type(sents[0]) == list:\n",
        "            output_sents = [[self.get_id_by_token(x) for x in line] for line in sents]\n",
        "        else:\n",
        "            output_sents = [self.get_id_by_token(x) for x in sents]\n",
        "            pass\n",
        "        return (output_sents)\n",
        "\n",
        "\n",
        "    def to_tensor(self, sent: List[str]):\n",
        "        \"\"\"Converts a sentence as a list of tokens into a tensor of indices.\n",
        "\n",
        "        sent: a sentence as a list of strings (tokens)\n",
        "        \"\"\"\n",
        "\n",
        "        my_list = self.tokens2ids(sent)\n",
        "        tensor_out = torch.tensor(my_list , dtype = torch.long , device = DEVICE)\n",
        "        return tensor_out\n",
        "        pass\n",
        "\n",
        "\n",
        "    def pad_sents(self, sents: List[List[str]]) -> List[List[str]]:\n",
        "        \"\"\"Pads list of sentences according to the longest sentence.\n",
        "\n",
        "        sents: sentences as a list of list of tokens (strings).\n",
        "        \"\"\"\n",
        "        sents_padded = []\n",
        "\n",
        "        sents_padded = sents\n",
        "        max_len = max(len(l) for l in sents)\n",
        "        for l in range (len(sents)):\n",
        "          for i in range (max_len - len(sents[l])):\n",
        "            sents_padded[l].append (self.pad_token)\n",
        "\n",
        "        pass\n",
        "\n",
        "        return sents_padded\n",
        "\n",
        "    def save(self, path: str):\n",
        "        \"\"\"Saves the vocab in a json file.\n",
        "\n",
        "        path: path to save the vocab in\n",
        "        \"\"\"\n",
        "        with open(path, 'w') as f:\n",
        "            json.dump(self.word2id, f)\n",
        "\n",
        "    @staticmethod\n",
        "    def load(path: str):\n",
        "        \"\"\"Loads vocab from a json file.\n",
        "\n",
        "        path: path to load the vocab from\n",
        "        \"\"\"\n",
        "        with open(path, 'r') as f:\n",
        "            word2id = json.load(f)\n",
        "\n",
        "        return Vocab(word2id)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "s44fwNO6ftyh",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Now let's create the vocabs using our source and target sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "20WsmLSifw-a",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "outputId": "1dce2e57-e218-4545-c88e-65ed7840382d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "src_vocab = Vocab()\n",
        "src_vocab.build(src_sents)\n",
        "tgt_vocab = Vocab()\n",
        "tgt_vocab.build(tgt_sents)\n",
        "\n",
        "# You could also set the size of the vocab and minimum frequency of the words if you'd like\n",
        "print('French Vocab Size:', src_vocab.size)\n",
        "print('English Vocab Size:', tgt_vocab.size)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French Vocab Size: 21335\n",
            "English Vocab Size: 13044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "xoD6TMSXXoiv",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "### 3.3 Creating Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "xiLWkpjbXtZ1",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Now Let's create datasets and dataloaders so that we can later use them for training our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "rABkKu9JXvhA",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "class NMTData(Dataset):\n",
        "    def __init__(self, src_sents: List[List[str]], tgt_sents: List[List[str]], transform):\n",
        "        self.src_sents = src_sents\n",
        "        self.tgt_sents = tgt_sents\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sents)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        sents = {'src': self.src_sents[item], 'tgt': self.tgt_sents[item]}\n",
        "        return self.transform(sents)\n",
        "\n",
        "\n",
        "# utility function for padding a tensor\n",
        "def pad_tensor(tensor: torch.Tensor, size: int, dim: int=-1):\n",
        "    \"\"\"\n",
        "    tensor: tensor to pad\n",
        "    size: the size to pad to\n",
        "    dim: dimension to pad\n",
        "\n",
        "    returns a new tensor padded to 'size' in dimension 'dim'\n",
        "    \"\"\"\n",
        "    pad_size = list(tensor.shape)\n",
        "    pad_size[dim] = size - tensor.size(dim)\n",
        "    pad = torch.full(pad_size, PAD_IDX, dtype=tensor.dtype, device=tensor.device)\n",
        "\n",
        "    return torch.cat([tensor, pad], dim=dim)\n",
        "\n",
        "\n",
        "# Thanks to https://discuss.pytorch.org/t/dataloader-for-various-length-of-data/6418/8\n",
        "class PadCollate:\n",
        "    \"\"\"\n",
        "    a variant of callate_fn that pads according to the longest sequence in\n",
        "    a batch of sequences\n",
        "    \"\"\"\n",
        "    def __init__(self, dim=-1):\n",
        "        \"\"\"\n",
        "        dim: the dimension to be padded (e.g., dimension of time in sequences)\n",
        "        \"\"\"\n",
        "        self.dim = dim\n",
        "\n",
        "    def pad_collate(self, batch):\n",
        "        \"\"\"\n",
        "        batch: a batch of data as a list of Dictionaries\n",
        "\n",
        "        returns:\n",
        "          src_sents: tensor of source sentences\n",
        "          tgt_sents: tensor of target sentences\n",
        "          src_lengths: lengths of source sentences before padding as a list\n",
        "        \"\"\"\n",
        "\n",
        "        # sort pairs based on the lengths of source sentences\n",
        "        batch = sorted(batch, key=lambda pair: pair['src'].size(0), reverse=True)\n",
        "        src_lengths = [pair['src'].size(0) for pair in batch]\n",
        "\n",
        "        # find longest sequence\n",
        "        max_len_src = max(map(lambda pair: pair['src'].shape[self.dim], batch))\n",
        "        max_len_tgt = max(map(lambda pair: pair['tgt'].shape[self.dim], batch))\n",
        "\n",
        "        # pad according to max_len\n",
        "        batch = list(map(lambda pair: (pad_tensor(pair['src'], size=max_len_src, dim=self.dim),\n",
        "                                       pad_tensor(pair['tgt'], size=max_len_tgt, dim=self.dim)),\n",
        "                         batch))\n",
        "\n",
        "        # stack all\n",
        "        src_sents = torch.stack([pair[0] for pair in batch], dim=-1)\n",
        "        tgt_sents = torch.stack([pair[1] for pair in batch], dim=-1)\n",
        "\n",
        "        return src_sents, tgt_sents, src_lengths\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        return self.pad_collate(batch)\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"A callable transform that converts sentences to Tensors.\n",
        "    \"\"\"\n",
        "    def __init__(self, src_vocab: Vocab, tgt_vocab: Vocab):\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tgt_vocab = tgt_vocab\n",
        "\n",
        "    def __call__(self, sents: Dict):\n",
        "        src_sent, tgt_sent = sents['src'], sents['tgt']\n",
        "\n",
        "        return {'src': self.src_vocab.to_tensor(src_sent),\n",
        "                'tgt': self.tgt_vocab.to_tensor(tgt_sent)}\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "8Y6ldOPRZ4kz",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Now let's create a sample dataloader and read a batch of data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "SuesGV3UZ-8H",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "outputId": "026898e1-179e-4488-b56f-c11be66b6cef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "set_seed(40719)\n",
        "dataset = NMTData(src_sents=src_sents, tgt_sents=tgt_sents,\n",
        "                  transform=ToTensor(src_vocab, tgt_vocab))\n",
        "dataloader = DataLoader(dataset, batch_size=5, shuffle=True, num_workers=0,\n",
        "                        collate_fn=PadCollate())\n",
        "\n",
        "src_sents_tensor, tgt_sents_tensor, src_lengths = next(iter(dataloader))\n",
        "print(src_sents_tensor, tgt_sents_tensor, src_lengths, sep='\\n\\n')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   23,    23,   116,    73,    23],\n",
            "        [  264,  1081, 16253,   247,   261],\n",
            "        [   53,    12,  1891,    12,    13],\n",
            "        [  250,  1258,   725,  5135,  2095],\n",
            "        [ 2141,  3159,   830,   133,    16],\n",
            "        [  232,    12, 16254,  2283,     0],\n",
            "        [ 2142,   122,    16,    16,     0],\n",
            "        [ 4475,   338,     0,     0,     0],\n",
            "        [   16,    16,     0,     0,     0]], device='cuda:0')\n",
            "\n",
            "tensor([[   1,    1,    1,    1,    1],\n",
            "        [  14,   14,  525,   62,   14],\n",
            "        [  24,   35, 9513,  349,   68],\n",
            "        [ 439, 3470,  352,   30, 1357],\n",
            "        [2419,  202,  374,   96,  525],\n",
            "        [ 334,   22, 3123,  130, 1968],\n",
            "        [2472, 1689, 4831,    5,    5],\n",
            "        [   5,  202,    5,    2,    2],\n",
            "        [   2, 1694,    2,    0,    0],\n",
            "        [   0,  170,    0,    0,    0],\n",
            "        [   0,    5,    0,    0,    0],\n",
            "        [   0,    2,    0,    0,    0]], device='cuda:0')\n",
            "\n",
            "[9, 9, 7, 7, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "feCVz6vd5uyL",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Now we are ready to code our Seq2Seq model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "paCGNCC25PpY",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "### 3.4 Seq2Seq with Attention Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "qsNJVJoOO8tC",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "In Machine Translation, our goal is to convert a sentence from the source language to the target language. In this assignment, we will implement a sequence-to-sequence (Seq2Seq) network with attention, to build a Neural Machine Translation (NMT) system. In this section, we describe the training procedure for the proposed NMT system:\n",
        "\n",
        "1. Given a sentence in the source language, we look up the word embeddings from the source embeddings matrix with the embedding dimension $e$.\n",
        "\n",
        "2. We feed these embeddings to the Encoder, yielding hidden states $h_{0}^{enc},...,h_{m}^{enc} \\in \\mathbb{R}^h$ where $h$ is the *hidden size* of the network and $m$ is the length of the source sequence.\n",
        "\n",
        "3. We then initialize the Decoder's first hidden state $h_0^{dec} \\in \\mathbb{R}^h$ by applying a linear projection (called *bridge*) on the Encoder's final hidden state.\n",
        "\n",
        "4. With the Decoder initialized, we must now feed it the matching sentence in the target language. On the $t$-th step, we look up the embedding for the $t$-th word (or token), $y_t \\in \\mathbb{R}^e$ where $e$ is the *embedding size*. Note that during the training procedure where we use teacher forcing, $y_t$ is the $t$-th word in the target sentence. However, in the test stage where we do not have a target sentence, the output word of the model at the previous time step will be used as $y_t$.\n",
        "\n",
        "5. We then concatenate $y_t$ with the combined-output vector from the previous timestep (the gray vector in the illustration below which is denoted by $\\tilde{h}$) to produce $\\hat{y}_{t} \\in \\mathbb{R}^{e+h}$. for the first target word (i.e. the start token), previous combined-output vector is a zero-vector. We then feed $\\hat{y}_{t}$ as input to the decoder.\n",
        "\n",
        "6. We use $h_t^{dec}$ to compute **dot attention** over $h_{0}^{enc},...,h_{m}^{enc}$ (please refer to the paper for the details about this type of attention). This will give us a combination of the Encoder's hidden states called the *context vector* (blue vector in the illustration).\n",
        "\n",
        "7. We concatenate the context vector with the decoder hidden state $h_{t}^{dec}$ at each step and apply a linear layer (called *attn_combine* in the code), Tanh, and Dropout to get the next combined-output vector.\n",
        "\n",
        "8. After doing the above procedure for all of the time steps (i.e. generating the combined outputs of all time steps), we will apply the target vocab projection layer to compute scores (logits) of producing different words in the target vocab at all of the time steps simultaneously.\n",
        "\n",
        "9. We then produce the log-probability **$P$**, using log-softmax function, over target words and sum the log probability of generating the correct word over all of the time steps. We then minimize negative value of this sum to train our network.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "FlKkEZH8sidK"
      },
      "source": [
        "The above algorithm will become clearer to you as we walk through their implementation step by step later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "vJ6OQ-2o6dIz",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "The following figure from the paper illustrates the attention mechanism we will implement. Note that without attention mechanism, the encoder creates a single vector which, in the ideal case, encodes the “meaning” of the input sequence into a single vector — a single point in some $h$ dimensional space of sentences. This vector will then be passed to the decoder to generate the desired output. This single vector carries the burden of encoding the entire sentence. But, with attention, the decoder network can “focus” on a different part of the encoder’s outputs for every step of the decoder’s own outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "0cS5iLuQZv-x",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "<p align=\"center\">\n",
        "<img src=\"https://i.imgur.com/RUmR1CU.png\" height=400/>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "PN2oUAje86jr",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Here is another illustration of the training procedure of our Seq2Seq model. Note that this figure shows stacked (multi-layer) RNNs as the Encoder and the Decoder. We will use a single layer rnn in our implementation. Note that `<s>` and `</s>` are START and END tokens [4].\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "42g1NRKH9M89",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "<p align=\"center\">\n",
        "<img src=\"https://imgur.com/download/Xf46eg0\" height=400/>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "MhC3bIYh0i4U",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Let's start coding the model. Here is the code of our encoder's class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "AiFB2kbXz9LS",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, hidden_size, embed_size: int, src_vocab_size: int):\n",
        "        \"\"\"\n",
        "        hidden_size: hidden size to be used for the RNN\n",
        "        embed_size: embedding size (dimension)\n",
        "        src_vocab_size: source language vocab's size\n",
        "        \"\"\"\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.src_vocab_size = src_vocab_size\n",
        "        self.rnn = nn.GRU(input_size= self.embed_size , hidden_size= self.hidden_size)\n",
        "        self.src_embedding = nn.Embedding(num_embeddings= self.src_vocab_size , embedding_dim= self.embed_size , padding_idx= PAD_IDX)\n",
        "\n",
        "        pass\n",
        "\n",
        "\n",
        "    def forward(self, src: torch.Tensor, src_lengths: List[int]):\n",
        "        \"\"\"\n",
        "        src: tensor of source sentences containing token's indices in the vocab\n",
        "        src_lengths: lengths of source sentences before padding\n",
        "        \"\"\"\n",
        "        enc_hiddens, last_hidden, enc_hiddens_mask = None, None, None\n",
        "        #1\n",
        "        embed_out = self.src_embedding(src)\n",
        "        #2\n",
        "        enc_hiddens , last_hidden = self.rnn(pack(embed_out , lengths= src_lengths))\n",
        "        enc_hiddens , lengths = unpack(enc_hiddens)\n",
        "        #3\n",
        "        enc_hiddens = enc_hiddens.permute(1 , 0 , 2)\n",
        "        #4\n",
        "        enc_hiddens_mask = self.generate_enc_hiddens_mask(enc_hiddens , lengths)\n",
        "        pass\n",
        "\n",
        "        return enc_hiddens, last_hidden, enc_hiddens_mask\n",
        "\n",
        "    def generate_enc_hiddens_mask(self, enc_hiddens: torch.Tensor, lengths: List[int]) -> torch.Tensor:\n",
        "        \"\"\"Generates mask which masks the encoder hidden states corresponding to <PAD> tokens\n",
        "        in the source sentences\n",
        "        \"\"\"\n",
        "        enc_masks = torch.zeros(enc_hiddens.shape[0], enc_hiddens.size(1), dtype=torch.float)\n",
        "        for iterator, length in enumerate(lengths):\n",
        "            enc_masks[iterator, length:] = 1\n",
        "\n",
        "        return enc_masks.to(DEVICE)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "GSmlbil70c3p",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Here is the code of our decoder's class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "XEq2afGM0X9f",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "class AttnDecoder(nn.Module):\n",
        "    def __init__(self, hidden_size: int, embed_size: int, tgt_vocab_size: int, dropout_rate=0.2):\n",
        "        \"\"\"\n",
        "        hidden_size: hidden size to be used for the RNN\n",
        "        embed_size: embedding size (dimension)\n",
        "        tgt_vocab_size: target language vocab size\n",
        "        dropout_rate: rate to be used for the dropout layer\n",
        "        \"\"\"\n",
        "        super(AttnDecoder, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.tgt_vocab_size = tgt_vocab_size\n",
        "        self.tgt_embedding = nn.Embedding(num_embeddings= self.tgt_vocab_size ,embedding_dim= self.embed_size\n",
        "                                          , padding_idx= PAD_IDX)\n",
        "        self.rnn = nn.GRUCell(self.embed_size + self.hidden_size  , self.hidden_size)\n",
        "        self.attn_combine = nn.Linear(2 *self.hidden_size , self.hidden_size , bias= False)\n",
        "        self.tgt_vocab_projection = nn.Linear(self.hidden_size , self.tgt_vocab_size , bias= False)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "\n",
        "        pass\n",
        "\n",
        "\n",
        "    def forward(self, enc_hiddens: torch.Tensor, enc_hiddens_mask: torch.Tensor,\n",
        "                dec_init_state: torch.Tensor, tgt: torch.Tensor):\n",
        "        \"\"\"Runs the teacher forcing algorithm and returns the scores (logits) of different words\n",
        "        across all of the time steps. The logits shape should be (seq_len_tgt-1, batch_size, tgt_vocab_size).\n",
        "\n",
        "        tgt: tensor of target sentences with shape (seq_len_tgt, batch_size)\n",
        "        enc_hiddens: tensor of the encoder hidden states with shape (batch_size, seq_len_src, hidden_size)\n",
        "        enc_hiddens_mask: tensor of the encoder hidden states with shape (batch_size, seq_len_src)\n",
        "        dec_init_state: decoder's initial hidden state\n",
        "        \"\"\"\n",
        "        # remove the <END> token from the longest sentence(s)\n",
        "        tgt = tgt[:-1]\n",
        "\n",
        "        # Initialize the decoder state\n",
        "        dec_state = dec_init_state\n",
        "\n",
        "        # Initialize previous combined output vector as zero\n",
        "        batch_size = enc_hiddens.size(0)\n",
        "        combined_output_prev = torch.zeros(batch_size, self.hidden_size, device=DEVICE )\n",
        "        # Initialize a list we will use to collect the combined output o_t at each step\n",
        "        combined_outputs = []\n",
        "        logits = None\n",
        "\n",
        "        embed_out = self.tgt_embedding(tgt)\n",
        "        #2\n",
        "        for i in range (embed_out.shape[0] ):\n",
        "          step_input = torch.cat((embed_out[i] , combined_output_prev) , 1)\n",
        "          dec_state , combined_output = self.step(step_input , dec_state , enc_hiddens , enc_hiddens_mask)\n",
        "          combined_outputs.append(combined_output)\n",
        "          combined_output_prev = combined_output\n",
        "        #3\n",
        "        combined_outputs = torch.stack(combined_outputs)\n",
        "        #4\n",
        "        logits = self.tgt_vocab_projection(combined_outputs)\n",
        "\n",
        "        pass\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def step(self, ybar_t: torch.Tensor, dec_state: torch.Tensor, enc_hiddens: torch.Tensor, enc_hiddens_mask):\n",
        "        \"\"\"\n",
        "        ybar_t: the input to be fed to the decoder at the current step with shape\n",
        "        dec_state: decodor's previous hidden state\n",
        "        enc_hiddens: encoder hidden states (outputs)\n",
        "        enc_hiddens_mask: mask generated during the encoding phase that masks <PAD>s\n",
        "\n",
        "        returns the current hidden state and combined output\n",
        "        \"\"\"\n",
        "        attn_scores_t, dec_state_t = None, None\n",
        "\n",
        "        #1\n",
        "        dec_state_t = self.rnn(ybar_t , dec_state)\n",
        "        #2\n",
        "        temp_dec = dec_state_t.reshape(dec_state_t.shape[0]  , dec_state_t.shape[1]  , 1 )\n",
        "        attn_scores_t = torch.bmm(enc_hiddens , temp_dec)\n",
        "        attn_scores_t = attn_scores_t.squeeze(2)\n",
        "        pass\n",
        "\n",
        "\n",
        "        # Set attn_scores_t to -inf where enc_hiddens_mask has 1, where there is a <PAD>\n",
        "        # in the source sentence.\n",
        "        if enc_hiddens_mask is not None:\n",
        "            attn_scores_t.data.masked_fill_(enc_hiddens_mask.bool(), -float('inf'))\n",
        "\n",
        "        combined_output_t = None\n",
        "\n",
        "        #1\n",
        "        weights = F.softmax(attn_scores_t , 1)\n",
        "        #2\n",
        "        weights = weights.reshape(weights.shape[0]  ,1, weights.shape[1]  )\n",
        "        contex_vector = torch.bmm(weights , enc_hiddens )\n",
        "        #3\n",
        "        contex_vector = contex_vector.squeeze(1)\n",
        "        contex_vector = torch.cat(( dec_state_t , contex_vector ) , 1)\n",
        "        combined_output_t = self.attn_combine(contex_vector)\n",
        "        #4\n",
        "        combined_output_t = torch.tanh(combined_output_t)\n",
        "        combined_output_t = self.dropout(combined_output_t)\n",
        "        pass\n",
        "\n",
        "        return dec_state_t, combined_output_t"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "Hwl7lCBVW22S",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "The following class is the whole Sequence-to-Sequence model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "ouguEZHiFhVS",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "class AttnSeq2Seq(nn.Module):\n",
        "    def __init__(self, hidden_size: int, embed_size: int, src_vocab_size: int,\n",
        "                 tgt_vocab_size: int, dropout_rate:float=0.2):\n",
        "        \"\"\"\n",
        "        hidden_size: hidden size (dimensionality) of the RNNs\n",
        "        embed_size: embedding size (dimensionality)\n",
        "        src_vocab_size: source sentences Vocabulary object\n",
        "        tgt_vocab_size: target sentences Vocabulary object\n",
        "        dropout_rate: dropout probability\n",
        "        \"\"\"\n",
        "        super(AttnSeq2Seq, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.src_vocab_size, self.tgt_vocab_size = src_vocab_size, tgt_vocab_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.encoder, self.decoder, self.bridge = None, None, None\n",
        "\n",
        "        self.encoder = Encoder(self.hidden_size , self.embed_size , self.src_vocab_size)\n",
        "        self.bridge = nn.Linear(self.hidden_size , self.hidden_size , bias = False)\n",
        "        self.decoder = AttnDecoder(self.hidden_size , self.embed_size , self.tgt_vocab_size , self.dropout_rate)\n",
        "        pass\n",
        "\n",
        "\n",
        "    def init_weights(self, val: float):\n",
        "\n",
        "        for p in self.parameters():\n",
        "          nn.init.uniform_(p , a= -val , b= val)\n",
        "        pass\n",
        "\n",
        "\n",
        "    def forward(self, src_tensor: torch.Tensor, tgt_tensor: torch.Tensor, src_lengths: List[int]):\n",
        "        \"\"\" Takes a mini-batch of source and target sentences, compute the log-likelihood of\n",
        "        target sentences under the language models learned by the neural machine translation\n",
        "        system.\n",
        "\n",
        "        src_tensor: tensor of source sentences\n",
        "        tgt: tensor of target sentences\n",
        "        src_lengths: lengths of source sentences before padding\n",
        "        \"\"\"\n",
        "        log_probs = None\n",
        "\n",
        "        #1\n",
        "        enc_outputs , enc_hidden , enc_hidden_mask = self.encoder(src_tensor , src_lengths)\n",
        "        #2\n",
        "        enc_hidden = enc_hidden.squeeze(0)\n",
        "        init_hidden = self.bridge(enc_hidden)\n",
        "        #3\n",
        "        logits = self.decoder(enc_outputs , enc_hidden_mask , init_hidden , tgt_tensor)\n",
        "        #4\n",
        "        log_probs = F.log_softmax(logits , -1)\n",
        "        pass\n",
        "\n",
        "        tgt_mask = (tgt_tensor != PAD_IDX).float()\n",
        "\n",
        "        # Compute log probability of generating true target words\n",
        "        tgt_gold_words_log_prob = torch.gather(log_probs, index=tgt_tensor[1:].unsqueeze(-1), dim=-1).squeeze(-1) * tgt_mask[1:]\n",
        "        # sum scores across different time steps of sequences (i.e. computing log probability of the sequences)\n",
        "        scores = tgt_gold_words_log_prob.sum(dim=0)\n",
        "\n",
        "        return scores\n",
        "    def greedy_decode(self, src_sent: torch.Tensor, tgt_vocab: Vocab, max_length: int = 50):\n",
        "        \"\"\"\n",
        "        src_sent: source sentence tensor with shape (seq_len, 1)\n",
        "        max_length: allowed maximum length of the target translation\n",
        "\n",
        "        returns decoded_sent: decoded translation of source sentence\n",
        "        \"\"\"\n",
        "        decoded_sent = []\n",
        "\n",
        "        enc_outputs , enc_hidden , enc_hidden_mask = self.encoder(src_sent , [len(src_sent)])\n",
        "        #not so sure about this one!!\n",
        "        enc_hidden_br = enc_hidden.squeeze(0)\n",
        "        dec_hidden = self.bridge(enc_hidden_br)\n",
        "        #or this one\n",
        "        start = torch.tensor([tgt_vocab.get_id_by_token('<START>')] , device= DEVICE)\n",
        "        embeded = self.decoder.tgt_embedding(start)\n",
        "        #even this :)\n",
        "        combined_output_prev = torch.zeros_like(dec_hidden)\n",
        "        i = 0\n",
        "        indice = -1\n",
        "        while i < max_length and not(indice == 2 ):\n",
        "          i += 1\n",
        "          step_input = torch.cat((embeded , combined_output_prev) , 1)\n",
        "          dec_hidden , combined_output = self.decoder.step(step_input , dec_hidden , enc_outputs , enc_hidden_mask)\n",
        "          logits =  self.decoder.tgt_vocab_projection(combined_output)\n",
        "          value, indice = logits.max(1)\n",
        "          embeded = self.decoder.tgt_embedding(torch.tensor([int(indice)] , device= DEVICE))\n",
        "          decode = tgt_vocab.get_token_by_id(int(indice))\n",
        "          decoded_sent.append(decode)\n",
        "          combined_output_prev = combined_output\n",
        "        pass\n",
        "\n",
        "\n",
        "        return decoded_sent\n",
        "\n",
        "    def count_parameters(self):\n",
        "        \"\"\"Counts the number of parameters of the model.\n",
        "        \"\"\"\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "    @staticmethod\n",
        "    def load(model_path: str):\n",
        "        \"\"\"Loads the model from a file.\n",
        "\n",
        "        model_path: the file's path to load the model from\n",
        "        \"\"\"\n",
        "        print('loading from [%s]' % model_path)\n",
        "        params = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
        "        args = params['args']\n",
        "        model = AttnSeq2Seq(**args)\n",
        "        model.load_state_dict(params['state_dict'])\n",
        "        return model\n",
        "\n",
        "    def save(self, path: str):\n",
        "        \"\"\"Saves the model's parameters to a file.\n",
        "\n",
        "        path: path for the model to be saved\n",
        "        \"\"\"\n",
        "        print(\"save model's parameters to [%s]\" % path)\n",
        "\n",
        "        params = {\n",
        "            'args': dict(hidden_size=self.hidden_size,\n",
        "                         embed_size=self.embed_size,\n",
        "                         src_vocab_size=self.src_vocab_size,\n",
        "                         tgt_vocab_size=self.tgt_vocab_size,\n",
        "                         dropout_rate=self.dropout_rate),\n",
        "            'state_dict': self.state_dict()\n",
        "        }\n",
        "\n",
        "        torch.save(params, path)\n",
        "\n",
        "\n",
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "1BST0pn40Nms",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "#### 3.4.1 Initialization\n",
        "Implement the `__init__()` methods of the AttnSeq2Seq, Encoder, and AttnDecoder.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "Hn5-CJxw0jyj",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "#### 3.4.2 Enocder\n",
        "Implement `forward()` method of the Encoder class. Note that you also have to implement calling this method from the AttnSeq2Seq model too. Let's test your imeplementation of Encoder with the following simple test:\n",
        "\n",
        "**NOTE: If you do not pass the test, please double check the order of instantiations in the constructor of Encoder class!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "m7y_uIJA2a6A",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "outputId": "aaae9fcb-d796-426c-e80c-905067c927d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def test_encoder():\n",
        "    set_seed(40719)\n",
        "    test_encoder = Encoder(hidden_size=3, embed_size=5, src_vocab_size=10)\n",
        "    test_encoder.to(DEVICE)\n",
        "    test_input = torch.tensor([[9, 5, 6, 8, 2, 6],\n",
        "                               [6, 5, 5, 2, 9, 0],\n",
        "                               [6, 2, 3, 0, 0, 0],\n",
        "                               [2, 3, 0, 0, 0, 0]]).t().to(DEVICE)\n",
        "\n",
        "    test_lengths = [6, 5, 3, 2]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_outputs = test_encoder(test_input, test_lengths)\n",
        "\n",
        "    enc_hiddens, last_hidden, enc_hiddens_mask = list(map(lambda x: x.cpu().numpy(), test_outputs))\n",
        "\n",
        "    assert last_hidden.shape == (1, 4, 3)\n",
        "    assert enc_hiddens.shape == (4, 6, 3)\n",
        "\n",
        "\n",
        "    assert np.linalg.norm(last_hidden - [[[-0.4525945,   0.54975474, -0.09157258],\n",
        "                                          [ 0.02271755,  0.39946806, -0.70311207],\n",
        "                                          [-0.59517485,  0.34378132, -0.02917046],\n",
        "                                          [-0.52983993,  0.38805154, -0.10685067]]]) < 1e-4\n",
        "\n",
        "\n",
        "    assert np.linalg.norm(enc_hiddens_mask - [[0., 0., 0., 0., 0., 0.],\n",
        "                                              [0., 0., 0., 0., 0., 1.],\n",
        "                                              [0., 0., 0., 1., 1., 1.],\n",
        "                                              [0., 0., 1., 1., 1., 1.]]) < 1e-8\n",
        "\n",
        "    print('passed!')\n",
        "\n",
        "\n",
        "test_encoder()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "1G2N4PON-qFy",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "#### 3.4.3 Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "Hcn9R61Xk235",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Implement `forward()` method of the AttnDecoder class. Note that you also have to implement calling this method from the AttnSeq2Seq model too. Let's test your imeplementation of AttnDecoder with the following simple test:\n",
        "\n",
        "**NOTE: If you do not pass the test, please double check the order of instantiations in the constructor of AttnDecoder class!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox_duRWLrRWK",
        "outputId": "a5e17b59-da86-49c2-de16-ed556c98eafa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def test_decoder():\n",
        "    set_seed(40719)\n",
        "    test_decoder = AttnDecoder(hidden_size=3, embed_size=5, tgt_vocab_size=5)\n",
        "    test_decoder.to(DEVICE)\n",
        "\n",
        "    test_enc_hiddens = torch.randn(2, 6, 3).to(DEVICE)\n",
        "\n",
        "    test_dec_init_state = torch.randn(2, 3).to(DEVICE)\n",
        "    test_enc_hiddens_mask = torch.tensor([[0., 0., 0., 0., 0., 0.],\n",
        "                                          [0., 0., 1., 1., 1., 1.]]).to(DEVICE)\n",
        "\n",
        "    test_tgt = torch.tensor([[1, 3, 4, 4, 2],\n",
        "                             [1, 3, 4, 2, 0]]).t().to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        logits = test_decoder(test_enc_hiddens, test_enc_hiddens_mask,\n",
        "                              test_dec_init_state, test_tgt)\n",
        "    assert np.linalg.norm(logits.cpu().numpy() - [[[-0.06004265,  0.25477493,  0.3830248,   0.00774992,  0.17179054],\n",
        "                                                   [-0.18582398,  0.13055463,  0.08564769, -0.25669473,  0.12312719]],\n",
        "                                                  [[ 0.05147437, -0.04828914,  0.02907404,  0.04513214,  0.01152593],\n",
        "                                                   [ 0.0291394,  -0.06567273, -0.02651883,  0.00318674, -0.00192575]],\n",
        "                                                  [[ 0.15429737, -0.02719174,  0.00957732,  0.2634642,  -0.09186685],\n",
        "                                                   [ 0.06497972, -0.03984828,  0.011322,    0.08325085, -0.01648209]],\n",
        "                                                  [[ 0.15074214, -0.11919288, -0.13798426,  0.21574639, -0.14181782],\n",
        "                                                   [-0.07257012, -0.01131682, -0.04402388, -0.13441817,  0.02880232]]]) < 1e-4\n",
        "    print('passed!')\n",
        "\n",
        "test_decoder()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "FtUhXa9XtNJL",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "#### 3.4.4 AttnSeq2Seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "iKyNIegcttlY",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Let's test your implementation of the `forward()` method of AttnSeq2Seq class:\n",
        "\n",
        "**NOTE: If you do not pass the test, please double check the order of instantiations in the constructors of Encoder, AttnDecoder, AttnSeq2Seq classes!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SNeT1YYrRWS",
        "outputId": "c603d17c-52c6-48ea-9961-2e77f0b9f178",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def test_attn_seq2seq():\n",
        "    set_seed(40719)\n",
        "\n",
        "    test_attn_seq2seq = AttnSeq2Seq(hidden_size=3, embed_size=5,\n",
        "                                  src_vocab_size=src_vocab.size, tgt_vocab_size=5)\n",
        "    test_attn_seq2seq.to(DEVICE)\n",
        "\n",
        "    test_src = torch.tensor([[11, 5, 6, 100, 2, 14],\n",
        "                             [2, 3, 0, 0, 0, 0]]).t().to(DEVICE)\n",
        "    test_src_lengths = [6, 2]\n",
        "    test_tgt = torch.tensor([[1, 3, 4, 4, 2],\n",
        "                             [1, 3, 4, 2, 0]]).t().to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        scores = test_attn_seq2seq(test_src, test_tgt, test_src_lengths)\n",
        "    assert np.linalg.norm(scores.cpu().numpy() - [-6.347041, -4.7729683]) < 1e-4\n",
        "\n",
        "    print('passed!')\n",
        "\n",
        "test_attn_seq2seq()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "PTtLqWyDqmoF",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "### 3.5 Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "3z9-sONeqpGR",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Now let's implement the following function to train your network.\n",
        "\n",
        "**Note that**:\n",
        "1. you will first call the train function in the debug mode (by setting ```debug = True``` in the args) and sanity-check your network on the 100 first samples in the corpus. In this case, set the maximum number of epochs to 200. After running for this amount of epochs, you have to witness a training error very close to 0.\n",
        "\n",
        "2. take the mean of the scores returned by the network across a batch. Use the negative value of this mean as the loss of a batch. You can take a running training loss which is the mean of the losses of batches fed to the model every `log_every` iterations and print it. Note that this running loss should converges to zero during sanity check.\n",
        "\n",
        "3. When ```debug = True``` there is no need for evaluation.\n",
        "\n",
        "4. You have to report running training loss every `log_every` iteration.\n",
        "\n",
        "5. You have to evaluate your network every `val_niter` iterations (only when ```debug = False```). For evaluation, simply report the mean value of loss across all of the validation samples. DO NOT forget to set the model to eval mode!\n",
        "\n",
        "6. As well as printing train and validation losses, save them throughout training in two lists and plot them after training is finished!\n",
        "\n",
        "7. Using techniques such as gradient clipping, early stopping, and learning rate decay (use it wisely!) will have bonus points.\n",
        "\n",
        "8. Don't forget to set `dropout_rate` to zero for sanity checking.\n",
        "\n",
        "9. After doing sanity check for 200 epochs, save your model in a file (you will load it later for greedy decoding).\n",
        "\n",
        "\n",
        "After doing sanity check and making sure that your network works fine, you can train your model on the entire corpus. In that case, you have to report the loss on the validation set too."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "hAN2wrtKsfaP",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Now let's call the train function and train your network on a tiny subset of the data (100 first samples) with the following cell. As we want the network to overfit on a tiny dataset, there is no need for validation set and evaluation.\n",
        "\n",
        "The hyperparameters specified for you below would probably give good results. But Feel free to change them if they do not work for you. (Do not change `debug` and `dropout_rate` hyperparams! Note that we turn off any kind of regularization during sanity check.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "06eUwPZ5nlE7",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "def train(args: Dict):\n",
        "    \"\"\"Trains the AttnSeq2Seq model.\n",
        "    args: arguments needed for training the model\n",
        "    \"\"\"\n",
        "    set_seed(40719)\n",
        "\n",
        "    batch_size = int(args['batch_size'])\n",
        "    log_every = int(args['log_every'])\n",
        "    debug = bool(args['debug'])\n",
        "\n",
        "    src_sents, tgt_sents = read_corpus(DATA_PATH)\n",
        "\n",
        "    if debug:\n",
        "        print('DEBUG MODE!')\n",
        "        # Use a tiny subset of sentences for sanity check\n",
        "        src_sents, tgt_sents = src_sents[:100], tgt_sents[:100]\n",
        "\n",
        "        train_dataset = NMTData(src_sents=src_sents, tgt_sents=tgt_sents,\n",
        "                                transform=ToTensor(src_vocab, tgt_vocab))\n",
        "\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                                      num_workers=0, collate_fn=PadCollate())\n",
        "    else:\n",
        "        print('TRAINING ON ENTIRE CORPUS!')\n",
        "        val_ratio = 0.01\n",
        "        val_size = int(len(src_sents) * val_ratio)\n",
        "        train_size = len(src_sents) - val_size\n",
        "\n",
        "        # Splitting the dataset to validation and training set\n",
        "        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                                      num_workers=0, collate_fn=PadCollate())\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True,\n",
        "                                    num_workers=0, collate_fn=PadCollate())\n",
        "\n",
        "        val_niter = int(args['val_niter'])\n",
        "\n",
        "\n",
        "\n",
        "    model = AttnSeq2Seq(embed_size=int(args['embed_size']),\n",
        "                        hidden_size=int(args['hidden_size']),\n",
        "                        dropout_rate=float(args['dropout_rate']),\n",
        "                        src_vocab_size=src_vocab.size,\n",
        "                        tgt_vocab_size=tgt_vocab.size)\n",
        "\n",
        "    model = model.to(DEVICE)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=float(args['lr']))\n",
        "\n",
        "    model.init_weights(0.1)\n",
        "    model.train()\n",
        "\n",
        "    print('Begin training')\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    epoch_num = int(args['max_epoch'])\n",
        "    log_every =  int(args['log_every'])\n",
        "    losses=[]\n",
        "    for epoch in range(epoch_num):\n",
        "      for i in range (len(iter(train_dataloader))):\n",
        "        model.train()\n",
        "        src, tgt, src_lengths = next(iter(train_dataloader))\n",
        "        model.zero_grad()\n",
        "        torch.nn.utils.clip_grad_value_(model.parameters() , 10.1)\n",
        "        scores = model(src , tgt, src_lengths)\n",
        "        loss = -1 * torch.mean(scores)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      if ( (epoch+1) % (log_every)== 0 ):\n",
        "        losses.append(loss.tolist())\n",
        "        print('Epoch num',epoch+1, 'mean training loss:'  , np.mean(losses))\n",
        "      if  epoch_num-1 % 50 == 0:\n",
        "        lr = float(args['lr']) / 10\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "      if not(debug):\n",
        "        if ((epoch+1) % (val_niter)== 0):\n",
        "          model.eval()\n",
        "          with torch.no_grad():\n",
        "            val_losses = []\n",
        "            for j in range (len (iter (val_dataloader))):\n",
        "              src_val, tgt_val, src_lengths_val = next(iter(val_dataloader))\n",
        "              val_scores = model(src_val , tgt_val , src_lengths_val)\n",
        "              val_loss = -(torch.mean(val_scores))\n",
        "              val_losses.append(val_loss.tolist())\n",
        "            print('Epoch num',epoch+1 ,  'mean validation loss' , np.mean(val_losses))\n",
        "    plt.plot(losses)\n",
        "    plt.ylabel('losses')\n",
        "    plt.show()\n",
        "    if (debug):\n",
        "      torch.save(model,'model_D')\n",
        "    else:\n",
        "      torch.save(model , 'model')\n",
        "    pass\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "xVtih06UrKmT",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "outputId": "8f4d8505-1427-4919-c300-1b1614540ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        }
      },
      "source": [
        "\"\"\"\n",
        "DESCRIPTION OF ARGUMENTS:\n",
        "\n",
        "log_every: determines how often (based on iterations) training loss should be printed\n",
        "out.\n",
        "\n",
        "val_niter: hyperparameter to determine how often evaluation on validation set\n",
        "should be done (used only when you want to train on the entire corpus).\n",
        "\n",
        "max_epoch: determines maximum number of epochs you want the model to be trained.\n",
        "When you reach this number of epochs, you should break the training loop.\n",
        "\n",
        "lr: learning rate\n",
        "\n",
        "uniform_init: will indicate the low and high values used for uniform initialization\n",
        "of the weights of the model (e.g. if it is 0.1, then initial weights would be\n",
        "distributed uniformly over (-0.1, +0.1)).\n",
        "\n",
        "debug: set it to True for sanity check and to False for training on entire\n",
        "corpus.\n",
        "\n",
        "This cell should run pretty fast on GPU. Training for 200 epochs on the first 100\n",
        "samples takes roughly 10 seconds for us.\n",
        "\"\"\"\n",
        "\n",
        "args = dict(batch_size=32, embed_size=256, hidden_size=256, dropout_rate=0.0,\n",
        "            uniform_init=0.1, lr=1e-3, log_every=10, max_epoch=200,\n",
        "            val_niter=None, debug=True)\n",
        "\n",
        "train(args)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading the corpus...\n",
            "DEBUG MODE!\n",
            "Begin training\n",
            "Epoch num 10 mean training loss: 7.078366279602051\n",
            "Epoch num 20 mean training loss: 5.473766922950745\n",
            "Epoch num 30 mean training loss: 4.138234217961629\n",
            "Epoch num 40 mean training loss: 3.3754220604896545\n",
            "Epoch num 50 mean training loss: 2.792038691043854\n",
            "Epoch num 60 mean training loss: 2.3638176222642264\n",
            "Epoch num 70 mean training loss: 2.0506452322006226\n",
            "Epoch num 80 mean training loss: 1.806801088154316\n",
            "Epoch num 90 mean training loss: 1.6161066939433415\n",
            "Epoch num 100 mean training loss: 1.4631476812064648\n",
            "Epoch num 110 mean training loss: 1.3372041644020514\n",
            "Epoch num 120 mean training loss: 1.2315318305045366\n",
            "Epoch num 130 mean training loss: 1.1418872515742595\n",
            "Epoch num 140 mean training loss: 1.0639591735920735\n",
            "Epoch num 150 mean training loss: 0.9985376762847106\n",
            "Epoch num 160 mean training loss: 0.9408883138094097\n",
            "Epoch num 170 mean training loss: 0.8890731003792847\n",
            "Epoch num 180 mean training loss: 0.8420505558864938\n",
            "Epoch num 190 mean training loss: 0.800598996250253\n",
            "Epoch num 200 mean training loss: 0.7613574327901006\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "t_5zo4XqyXcG",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "### 3.6 Greedy Decode and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "s3jfZbR3yRyp",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Implement `greedy_decode()` method of AttnSeq2Seq. This method will generate the translation of a single sentence in the target langauge using the greedy decoding algorithm.\n",
        "\n",
        "Test your implementation with the following function which runs greedy decoding for the model you trained and saved on the first 100 samples and prints out the sentences for which your output does not match the ground truth output. As your model has overfitted on the first 100 sentences, ALMOST all of your outputs must match the gournd truth outputs and only a couple of sentences should be printed out!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "h4dRbMJKyhul",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "outputId": "44e62f3f-26c9-44b0-cc71-8d43072b3d7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def evaluate_sanity():\n",
        "    ################################################################################\n",
        "    # TODO: 1) Load a pretrained model                                             #\n",
        "    ################################################################################\n",
        "\n",
        "    model = torch.load('model_D')\n",
        "\n",
        "    pass\n",
        "    ################################################################################\n",
        "    #                                 END OF YOUR CODE                             #\n",
        "    ################################################################################\n",
        "    src_sents, tgt_sents = read_corpus(DATA_PATH)\n",
        "    src_sents, tgt_sents = src_sents[:100], tgt_sents[:100]\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    print('\\nformat of prints: [sample-index] [source-sentence] [your-translation] [ground-truth-translation]\\n')\n",
        "    for it, (src_sent, tgt_sent) in enumerate(zip(src_sents, tgt_sents)):\n",
        "        src_sent_tensor = src_vocab.to_tensor(src_sent).unsqueeze(1)\n",
        "        if ['<START>'] + model.greedy_decode(src_sent_tensor, tgt_vocab) != tgt_sent:\n",
        "            print(it+1, src_sent, ['<START>'] + model.greedy_decode(src_sent=src_sent_tensor, tgt_vocab=tgt_vocab),\n",
        "                  '\\t', tgt_sent)\n",
        "\n",
        "evaluate_sanity()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading the corpus...\n",
            "\n",
            "format of prints: [sample-index] [source-sentence] [your-translation] [ground-truth-translation]\n",
            "\n",
            "22 ['merci', '!'] ['<START>', 'thanks', '.', '<END>'] \t ['<START>', 'cheers', '!', '<END>']\n",
            "78 ['degage', '!'] ['<START>', 'go', 'away', '!', '<END>'] \t ['<START>', 'beat', 'it', '.', '<END>']\n",
            "88 ['allez', '!'] ['<START>', 'come', 'on', '!', '<END>'] \t ['<START>', 'come', 'on', '.', '<END>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "2muncpfeynNI",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "After making sure that your network works fine, now let's set ```debug = False``` and train your network on the entire corpus. This time, you also need to report loss on the validation set. Before running the following cell, please pay attention to the notes mentioned in the text cell before the train loop. Don't forget to plot your results afterwards (feel free to return any values you need from the train function.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "zIKDn4WdcRnm",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "outputId": "fbc1cb1d-7c79-49f5-9e8a-c865acdc3120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        }
      },
      "source": [
        "args = dict(batch_size=256, embed_size=256, hidden_size=256, dropout_rate=0.2,\n",
        "            uniform_init=0.1, lr=1e-3, log_every=10, max_epoch=100,\n",
        "            val_niter=10, debug=False)\n",
        "\n",
        "train(args)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading the corpus...\n",
            "TRAINING ON ENTIRE CORPUS!\n",
            "Begin training\n",
            "Epoch num 10 mean training loss: 4.580414772033691\n",
            "Epoch num 10 mean validation loss 9.131394306818644\n",
            "Epoch num 20 mean training loss: 3.4611656665802\n",
            "Epoch num 20 mean validation loss 8.597150802612305\n",
            "Epoch num 30 mean training loss: 2.8610806465148926\n",
            "Epoch num 30 mean validation loss 10.240750948588053\n",
            "Epoch num 40 mean training loss: 2.4904529452323914\n",
            "Epoch num 40 mean validation loss 10.725408554077148\n",
            "Epoch num 50 mean training loss: 2.220949578285217\n",
            "Epoch num 50 mean validation loss 12.157597064971924\n",
            "Epoch num 60 mean training loss: 2.0211597879727683\n",
            "Epoch num 60 mean validation loss 12.103623549143473\n",
            "Epoch num 70 mean training loss: 1.8663606473377772\n",
            "Epoch num 70 mean validation loss 12.757867177327475\n",
            "Epoch num 80 mean training loss: 1.7626219540834427\n",
            "Epoch num 80 mean validation loss 12.241875330607096\n",
            "Epoch num 90 mean training loss: 1.6549915671348572\n",
            "Epoch num 90 mean validation loss 13.242698351542154\n",
            "Epoch num 100 mean training loss: 1.5593981325626374\n",
            "Epoch num 100 mean validation loss 12.588652769724527\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "otf1uVZEt9o_",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Now let's use your trained model to generate translations of a random sample of validation sentences in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "tq9JxChUuPoO",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fca875b-f95d-4ab4-8e08-e8b021c15d09"
      },
      "source": [
        "def evaluate():\n",
        "    ################################################################################\n",
        "    # TODO: 1) Load a model pretrained on the entire corpus                        #\n",
        "    ################################################################################\n",
        "    model = torch.load('model')\n",
        "    pass\n",
        "    ################################################################################\n",
        "    #                                 END OF YOUR CODE                             #\n",
        "    ################################################################################\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    set_seed(40719)\n",
        "    src_sents, tgt_sents = read_corpus(DATA_PATH)\n",
        "    val_ratio = 0.01\n",
        "    val_size = int(len(src_sents) * val_ratio)\n",
        "    train_size = len(src_sents) - val_size\n",
        "\n",
        "    _, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    print('\\nformat of prints: [source-sentence] [your-translation] [ground-truth-translation]\\n')\n",
        "\n",
        "    idxs = np.random.randint(0, len(val_dataset), 50)\n",
        "\n",
        "    for idx in idxs:\n",
        "        src_sent_tensor, tgt_sent_tensor = val_dataset[idx]['src'], val_dataset[idx]['tgt']\n",
        "        src_sent = [src_vocab.get_token_by_id(el.item()) for el in src_sent_tensor]\n",
        "        tgt_sent = [tgt_vocab.get_token_by_id(el.item()) for el in tgt_sent_tensor]\n",
        "        print('source sentence:\\n\\t', src_sent)\n",
        "        print('Your translation:\\n\\t', ['<START>'] + model.greedy_decode(src_sent_tensor.unsqueeze(1), tgt_vocab))\n",
        "        print('Ground truth translation:\\n\\t', tgt_sent, '\\n\\n')\n",
        "\n",
        "evaluate()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading the corpus...\n",
            "\n",
            "format of prints: [source-sentence] [your-translation] [ground-truth-translation]\n",
            "\n",
            "source sentence:\n",
            "\t ['que', 'dites', 'vous', 'd', 'aller', 'voir', 'un', 'film', 'ce', 'soir', '?']\n",
            "Your translation:\n",
            "\t ['<START>', 'how', 'about', 'eating', 'see', 'a', 'movie', 'tonight', '?', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'how', 'about', 'going', 'to', 'see', 'a', 'movie', 'tonight', '?', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['c', 'est', 'tout', 'ce', 'que', 'nous', 'faisons', 'ici', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'that', 's', 'all', 'we', 'do', 'here', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'that', 's', 'all', 'we', 'do', 'here', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['elle', 'passe', 'tout', 'son', 'temps', 'a', 'penser', 'aux', 'garcons', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'she', 'spends', 'all', 'at', 'doing', 'anything', 'time', 'thinking', 'about', 'boys', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'she', 'spends', 'all', 'her', 'time', 'thinking', 'about', 'boys', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['ce', 'n', 'est', 'pas', 'si', 'facile', 'd', 'apprendre', 'une', 'nouvelle', 'langue', 'apres', 'cinquante', 'ans', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'it', 's', 'not', 'so', 'easy', 'to', 'learn', 'a', 'new', 'language', 'after', 'years', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'it', 's', 'not', 'that', 'easy', 'to', 'learn', 'a', 'new', 'language', 'after', 'fifty', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['c', 'est', 'mon', 'affaire', 'a', 'moi', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'that', 'is', 'my', 'business', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'that', 'is', 'my', 'own', 'affair', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['un', 'pub', 'est', 'un', 'endroit', 'ou', 'les', 'gens', 'se', 'rassemblent', 'pour', 'boire', 'de', 'la', 'biere', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'one', 'place', 'is', 'a', 'place', 'where', 'people', 'might', 'collect', 'people', 'for', 'the', 'beer', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'a', 'pub', 'is', 'a', 'popular', 'gathering', 'place', 'in', 'which', 'to', 'drink', 'beer', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['pekin', 'est', 'la', 'capitale', 'de', 'la', 'chine', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'beijing', 'is', 'capital', 'of', 'china', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'beijing', 'is', 'the', 'capital', 'of', 'china', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['je', 'prefere', 'les', 'trains', 'aux', 'bus', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'i', 'prefer', 'to', 'touch', 'trains', 'on', 'the', 'bus', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'i', 'like', 'trains', 'better', 'than', 'buses', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['je', 'veux', 'm', 'en', 'debarrasser', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'i', 'want', 'to', 'get', 'it', 'over', 'with', 'it', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'i', 'want', 'to', 'get', 'rid', 'of', 'it', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['il', 'eut', 'beau', 'essayer', 'mon', 'opinion', 'ne', 'changea', 'pas', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'no', 'matter', 'how', 'hard', 'he', 'tried', 'my', 'opinion', 'didn', 't', 'change', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'no', 'matter', 'how', 'hard', 'he', 'tried', 'my', 'opinion', 'didn', 't', 'change', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['je', 'veux', 'savoir', 'de', 'quoi', 'il', 's', 'agit', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'i', 'want', 'to', 'know', 'what', 'that', 'is', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'i', 'want', 'to', 'know', 'what', 'it', 'is', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['j', 'en', 'ferai', 'l', 'essai', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'i', 'll', 'give', 'it', 'away', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'i', 'll', 'give', 'it', 'a', 'try', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['il', 'n', 'a', 'pas', 'travaille', 'dimanche', 'soir', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'he', 'didn', 't', 'work', 'on', 'sundays', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'he', 'did', 'not', 'work', 'on', 'sunday', 'night', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['est', 'ce', 'tout', 'ce', 'qu', 'il', 'y', 'a', '?']\n",
            "Your translation:\n",
            "\t ['<START>', 'is', 'that', 'all', 'there', 'is', '?', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'is', 'this', 'all', 'there', 'is', '?', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['tu', 'seras', 'tout', 'a', 'fait', 'remis', 'dans', 'quelques', 'jours', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'you', 'will', 'be', 'all', 'right', 'again', 'in', 'a', 'couple', 'of', 'days', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'you', 'will', 'be', 'all', 'right', 'again', 'in', 'a', 'couple', 'of', 'days', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['aide', 'moi', 'rien', 'que', 'pour', 'une', 'minute', '!']\n",
            "Your translation:\n",
            "\t ['<START>', 'help', 'me', 'anything', 'for', 'a', 'minute', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'help', 'me', 'for', 'just', 'a', 'minute', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['je', 'suis', 'un', 'etranger', 'ici', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'i', 'am', 'a', 'stranger', 'here', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'i', 'm', 'a', 'stranger', 'here', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['j', 'aime', 'vraiment', 'les', 'chiens', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'i', 'really', 'like', 'dogs', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'i', 'like', 'dogs', 'very', 'much', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['je', 'dois', 'prendre', 'rendez', 'vous', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'i', 'must', 'take', 'you', 'to', 'take', 'a', 'date', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'i', 'need', 'to', 'make', 'an', 'appointment', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['quelque', 'chose', 'n', 'est', 'pas', 'correct', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'something', 'is', 'not', 'right', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'something', 'isn', 't', 'right', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['j', 'assiste', 'a', 'des', 'conferences', 'scientifiques', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'i', 'm', 'catching', 'to', 'conferences', 'are', 'scientists', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'i', 'attend', 'scientific', 'conferences', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['qu', 'ai', 'je', 'fait', 'de', 'mal', '?']\n",
            "Your translation:\n",
            "\t ['<START>', 'what', 'did', 'i', 'do', 'wrong', '?', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'what', 'did', 'i', 'do', 'wrong', '?', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['je', 'ne', 'voulais', 'pas', 'attendre', 'apres', 'quoi', 'que', 'ce', 'soit', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'i', 'didn', 't', 'want', 'to', 'wait', 'for', 'anything', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'i', 'didn', 't', 'want', 'to', 'wait', 'for', 'anything', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['tom', 'et', 'mary', 'etaient', 'de', 'bons', 'amis', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'tom', 'and', 'mary', 'were', 'good', 'friends', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'tom', 'and', 'mary', 'used', 'to', 'be', 'good', 'friends', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['l', 'anglais', 'est', 'enseigne', 'dans', 'la', 'plupart', 'des', 'pays', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'english', 'is', 'taught', 'in', 'most', 'countries', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'english', 'is', 'taught', 'in', 'most', 'countries', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['c', 'est', 'parti', '!']\n",
            "Your translation:\n",
            "\t ['<START>', 'left', '!', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'here', 'we', 'go', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['comment', 'est', 'ce', 'que', 'tu', 't', 'appelles', '?']\n",
            "Your translation:\n",
            "\t ['<START>', 'what', 's', 'your', 'name', '?', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'what', 'are', 'you', 'called', '?', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['je', 'vous', 'ai', 'achete', 'un', 'cadeau', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'i', 'bought', 'you', 'a', 'gift', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'i', 'bought', 'you', 'a', 'present', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['je', 'ne', 'me', 'fais', 'pas', 'de', 'soucis', 'pour', 'l', 'argent', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'i', 'do', 'not', 'worry', 'for', 'money', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'i', 'm', 'not', 'worried', 'about', 'money', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['je', 'ne', 'faisais', 'que', 'dire', 'mes', 'prieres', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'i', 'wasn', 't', 'to', 'say', 'to', 'my', 'opinion', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'i', 'was', 'only', 'saying', 'my', 'prayers', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['vous', 'm', 'oublierez', 'un', 'jour', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'you', 'are', 'giving', 'me', 'a', 'day', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'you', 'll', 'forget', 'about', 'me', 'someday', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['allons', 'prendre', 'quelque', 'chose', 'a', 'manger', '!']\n",
            "Your translation:\n",
            "\t ['<START>', 'let', 's', 'go', 'take', 'something', 'to', 'eat', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'let', 's', 'get', 'something', 'to', 'eat', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['j', 'ai', 'couru', 'dehors', 'et', 'la', 'porte', 's', 'est', 'refermee', 'derriere', 'moi', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'i', 'ran', 'outside', 'and', 'the', 'door', 'made', 'up', 'behind', 'me', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'i', 'ran', 'outside', 'and', 'the', 'door', 'locked', 'itself', 'behind', 'me', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['ils', 'viennent', 'juste', 'd', 'arriver', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'they', 've', 'just', 'arrived', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'they', 'have', 'just', 'arrived', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['cette', 'maison', 'n', 'est', 'pas', 'a', 'vendre', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'this', 'house', 'is', 'not', 'for', 'sale', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'this', 'house', 'is', 'not', 'for', 'sale', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['nos', 'intentions', 'etaient', 'bonnes', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'our', 'intentions', 'were', 'good', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'we', 'meant', 'well', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['aujourd', 'hui', 'c', 'est', 'le', 'jour', 'le', 'plus', 'chaud', 'de', 'l', 'annee', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'today', 'is', 'the', 'hottest', 'day', 'in', 'the', 'year', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'today', 'is', 'the', 'hottest', 'day', 'this', 'year', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['lorsque', 'je', 'me', 'suis', 'reveille', 'ce', 'matin', 'je', 'me', 'sentais', 'malade', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'when', 'i', 'woke', 'up', 'this', 'morning', 'i', 'felt', 'sick', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'when', 'i', 'woke', 'up', 'this', 'morning', 'i', 'felt', 'sick', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['cette', 'maison', 'n', 'est', 'pas', 'a', 'vendre', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'this', 'house', 'is', 'not', 'for', 'sale', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'this', 'house', 'is', 'not', 'for', 'sale', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['c', 'est', 'tres', 'propre', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'it', 's', 'very', 'clean', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'it', 's', 'very', 'clean', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['croyez', 'en', 'moi', '!']\n",
            "Your translation:\n",
            "\t ['<START>', 'trust', 'me', 'on', 'that', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'trust', 'me', 'on', 'that', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['tous', 'les', 'mecs', 'm', 'ont', 'charriee', 'avec', 'ca', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'all', 'the', 'guys', 'got', 'to', 'me', 'with', 'that', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'all', 'the', 'guys', 'teased', 'me', 'about', 'it', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['je', 'prefere', 'le', 'vin', 'rouge', 'au', 'blanc', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'i', 'prefer', 'red', 'wine', 'to', 'white', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'i', 'prefer', 'red', 'wine', 'to', 'white', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['t', 'ai', 'je', 'entendue', 'parler', 'a', 'quelqu', 'un', '?']\n",
            "Your translation:\n",
            "\t ['<START>', 'did', 'i', 'hear', 'you', 'talking', 'to', 'someone', '?', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'did', 'i', 'hear', 'you', 'talking', 'to', 'someone', '?', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['son', 'travail', 'l', 'absorbe', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'his', 'job', 'consists', 'of', 'his', 'absorb', 'elephant', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'he', 'is', 'absorbed', 'in', 'his', 'work', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['j', 'etais', 'tres', 'fatigue', 'mais', 'j', 'etais', 'quand', 'meme', 'incapable', 'de', 'dormir', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'i', 'was', 'very', 'tired', 'but', 'i', 'could', 'not', 'even', 'sleep', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'i', 'was', 'very', 'tired', 'but', 'i', 'was', 'nevertheless', 'unable', 'to', 'sleep', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['nous', 'ne', 'saurons', 'jamais', 'qui', 'il', 'est', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'we', 'll', 'never', 'know', 'who', 'he', 'is', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'we', 'll', 'never', 'know', 'who', 'he', 'is', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['ce', 'n', 'est', 'pas', 'si', 'facile', 'd', 'apprendre', 'une', 'nouvelle', 'langue', 'apres', 'cinquante', 'ans', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'it', 's', 'not', 'so', 'easy', 'to', 'learn', 'a', 'new', 'language', 'after', 'years', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'it', 's', 'not', 'that', 'easy', 'to', 'learn', 'a', 'new', 'language', 'after', 'fifty', '.', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['etaient', 'ils', 'hier', 'a', 'la', 'bibliotheque', '?']\n",
            "Your translation:\n",
            "\t ['<START>', 'were', 'they', 'yesterday', '?', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'were', 'they', 'in', 'the', 'library', 'yesterday', '?', '<END>'] \n",
            "\n",
            "\n",
            "source sentence:\n",
            "\t ['venez', 'a', 'nous', '.']\n",
            "Your translation:\n",
            "\t ['<START>', 'come', 'to', 'us', '.', '<END>']\n",
            "Ground truth translation:\n",
            "\t ['<START>', 'come', 'to', 'us', '.', '<END>'] \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "sH-PhLGEsieu"
      },
      "source": [
        "**Note**: If you have implemented everything right, You should see that your network generates some of the translations correctly, some of its outputs mismatch in only a couple of words with the ground truth output, and some of them are even worse than that! <br/>\n",
        "You will witness that sometimes your network repeats generating a single word consecutively for multiple time steps and then after that the translation goes completely in the wrong way! In fact, these are all drawbacks of greedy decoding algorithm. As the network gets its own output, once one output is wrong, the network gets lost and can can generate garbage translation afterwards! There is an algorithm called **beam search** which amis to fix this issue and can generate much better outputs. But, it is outside the scope of our class. Interested students can search and read more about this algorithm on the Internet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "bPnw_vPjIiD3",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "**One final point**: Note that there are some advanced packages out there such as, spaCy and torchtext, that can help you automate many of the tasks we did above manullay (e.g. preprocessing, masking, reading the sequences, and etc.). Now that you have learned what's under the hood of training a Seq2Seq model, you can use these packages to make developing your Seq2Seq model easier from this point onwards!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG0_Hr56pJj8"
      },
      "source": [
        "### 3.7 Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3r5rMBbqNpz"
      },
      "source": [
        "- Check and review your answers. Make sure all cells' output are what you have planned.\n",
        "- Select File > Save.\n",
        "- To download the notebook, select File > Download .ipynb.\n",
        "- Create an archive of all notebooks (P1.ipynb, P2.ipynb, and P3.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "e392uwzbj29j",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "### 3.8 References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "2FponxifRlYJ",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "[1] Minh-Thang Luong, Hieu Pham, Christopher D. Manning, \"Effective Approaches to Attention-based Neural Machine Translation\", CoRR 2015 https://arxiv.org/abs/1508.04025.\n",
        "\n",
        "[2] PyTorch Sequence to Sequence Machine Translation Tutorial https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "\n",
        "[3] CS224N, Stanford University, Assignment 4\n",
        "\n",
        "[4] https://colab.research.google.com/drive/1uFJBO1pgsiFwCGIJwZlhUzaJ2srDbtw-"
      ]
    }
  ]
}